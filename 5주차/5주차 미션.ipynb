{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99041dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quiz 1\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "root = './data'\n",
    "mnist_train = dset.MNIST(root=root, train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = dset.MNIST(root=root, train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae8b6634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2731,  0.3375,  0.1582,  ...,  0.7269,  0.8668,  0.1255],\n",
       "        [ 0.0744,  0.6831,  0.3122,  ...,  0.7408, -0.1900,  1.6641],\n",
       "        [ 1.0756,  1.5867, -0.0803,  ..., -1.3937,  0.2254,  0.8176],\n",
       "        ...,\n",
       "        [ 0.7233,  0.0213,  0.4726,  ..., -0.1498,  1.6609,  0.8554],\n",
       "        [ 1.3822, -1.0026,  0.5326,  ..., -0.7408,  0.1800, -0.9022],\n",
       "        [ 0.6672,  1.3645, -1.1123,  ..., -1.8661,  0.9046,  0.1023]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quiz 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "linear = torch.nn.Linear(784, 10, bias = True).to(device) #softmax\n",
    "torch.nn.init.normal_(linear.weight) #weight linit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d277412",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quiz 3\n",
    "#Loss fn - cross Entropy Loss\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "#optimizer - SGD\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b523cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/15], Step[100/600], Loss: 4.0898, Accuracy: 41.00%\n",
      "Epoch[1/15], Step[200/600], Loss: 1.7256, Accuracy: 70.00%\n",
      "Epoch[1/15], Step[300/600], Loss: 1.7750, Accuracy: 62.00%\n",
      "Epoch[1/15], Step[400/600], Loss: 0.8882, Accuracy: 78.00%\n",
      "Epoch[1/15], Step[500/600], Loss: 1.2919, Accuracy: 70.00%\n",
      "Epoch[1/15], Step[600/600], Loss: 1.5846, Accuracy: 71.00%\n",
      "Epoch[2/15], Step[100/600], Loss: 1.0821, Accuracy: 76.00%\n",
      "Epoch[2/15], Step[200/600], Loss: 0.9890, Accuracy: 79.00%\n",
      "Epoch[2/15], Step[300/600], Loss: 1.1451, Accuracy: 82.00%\n",
      "Epoch[2/15], Step[400/600], Loss: 1.0064, Accuracy: 78.00%\n",
      "Epoch[2/15], Step[500/600], Loss: 1.5315, Accuracy: 75.00%\n",
      "Epoch[2/15], Step[600/600], Loss: 1.1116, Accuracy: 81.00%\n",
      "Epoch[3/15], Step[100/600], Loss: 0.8846, Accuracy: 86.00%\n",
      "Epoch[3/15], Step[200/600], Loss: 0.9137, Accuracy: 83.00%\n",
      "Epoch[3/15], Step[300/600], Loss: 1.0880, Accuracy: 80.00%\n",
      "Epoch[3/15], Step[400/600], Loss: 0.7421, Accuracy: 81.00%\n",
      "Epoch[3/15], Step[500/600], Loss: 0.7415, Accuracy: 80.00%\n",
      "Epoch[3/15], Step[600/600], Loss: 0.7156, Accuracy: 84.00%\n",
      "Epoch[4/15], Step[100/600], Loss: 0.5001, Accuracy: 86.00%\n",
      "Epoch[4/15], Step[200/600], Loss: 0.4225, Accuracy: 89.00%\n",
      "Epoch[4/15], Step[300/600], Loss: 0.4442, Accuracy: 91.00%\n",
      "Epoch[4/15], Step[400/600], Loss: 0.8889, Accuracy: 80.00%\n",
      "Epoch[4/15], Step[500/600], Loss: 0.7989, Accuracy: 83.00%\n",
      "Epoch[4/15], Step[600/600], Loss: 0.9461, Accuracy: 81.00%\n",
      "Epoch[5/15], Step[100/600], Loss: 0.9492, Accuracy: 79.00%\n",
      "Epoch[5/15], Step[200/600], Loss: 0.9686, Accuracy: 80.00%\n",
      "Epoch[5/15], Step[300/600], Loss: 0.4830, Accuracy: 89.00%\n",
      "Epoch[5/15], Step[400/600], Loss: 0.4025, Accuracy: 89.00%\n",
      "Epoch[5/15], Step[500/600], Loss: 0.6405, Accuracy: 88.00%\n",
      "Epoch[5/15], Step[600/600], Loss: 0.6125, Accuracy: 85.00%\n",
      "Epoch[6/15], Step[100/600], Loss: 0.8954, Accuracy: 87.00%\n",
      "Epoch[6/15], Step[200/600], Loss: 0.6710, Accuracy: 85.00%\n",
      "Epoch[6/15], Step[300/600], Loss: 0.7540, Accuracy: 85.00%\n",
      "Epoch[6/15], Step[400/600], Loss: 0.2719, Accuracy: 91.00%\n",
      "Epoch[6/15], Step[500/600], Loss: 0.6754, Accuracy: 86.00%\n",
      "Epoch[6/15], Step[600/600], Loss: 0.8655, Accuracy: 85.00%\n",
      "Epoch[7/15], Step[100/600], Loss: 0.7831, Accuracy: 81.00%\n",
      "Epoch[7/15], Step[200/600], Loss: 0.5547, Accuracy: 84.00%\n",
      "Epoch[7/15], Step[300/600], Loss: 0.7551, Accuracy: 83.00%\n",
      "Epoch[7/15], Step[400/600], Loss: 0.6520, Accuracy: 91.00%\n",
      "Epoch[7/15], Step[500/600], Loss: 0.6102, Accuracy: 82.00%\n",
      "Epoch[7/15], Step[600/600], Loss: 0.6302, Accuracy: 84.00%\n",
      "Epoch[8/15], Step[100/600], Loss: 0.3717, Accuracy: 93.00%\n",
      "Epoch[8/15], Step[200/600], Loss: 0.5808, Accuracy: 88.00%\n",
      "Epoch[8/15], Step[300/600], Loss: 0.6760, Accuracy: 81.00%\n",
      "Epoch[8/15], Step[400/600], Loss: 0.6929, Accuracy: 85.00%\n",
      "Epoch[8/15], Step[500/600], Loss: 0.4636, Accuracy: 88.00%\n",
      "Epoch[8/15], Step[600/600], Loss: 0.5781, Accuracy: 85.00%\n",
      "Epoch[9/15], Step[100/600], Loss: 0.4306, Accuracy: 87.00%\n",
      "Epoch[9/15], Step[200/600], Loss: 0.5930, Accuracy: 84.00%\n",
      "Epoch[9/15], Step[300/600], Loss: 0.4907, Accuracy: 89.00%\n",
      "Epoch[9/15], Step[400/600], Loss: 0.3143, Accuracy: 90.00%\n",
      "Epoch[9/15], Step[500/600], Loss: 0.4126, Accuracy: 88.00%\n",
      "Epoch[9/15], Step[600/600], Loss: 0.5477, Accuracy: 86.00%\n",
      "Epoch[10/15], Step[100/600], Loss: 0.8448, Accuracy: 83.00%\n",
      "Epoch[10/15], Step[200/600], Loss: 0.4541, Accuracy: 89.00%\n",
      "Epoch[10/15], Step[300/600], Loss: 0.5992, Accuracy: 86.00%\n",
      "Epoch[10/15], Step[400/600], Loss: 0.4357, Accuracy: 87.00%\n",
      "Epoch[10/15], Step[500/600], Loss: 0.2650, Accuracy: 92.00%\n",
      "Epoch[10/15], Step[600/600], Loss: 0.5465, Accuracy: 86.00%\n",
      "Epoch[11/15], Step[100/600], Loss: 0.4259, Accuracy: 88.00%\n",
      "Epoch[11/15], Step[200/600], Loss: 0.4991, Accuracy: 85.00%\n",
      "Epoch[11/15], Step[300/600], Loss: 0.4807, Accuracy: 87.00%\n",
      "Epoch[11/15], Step[400/600], Loss: 0.7030, Accuracy: 81.00%\n",
      "Epoch[11/15], Step[500/600], Loss: 0.3393, Accuracy: 89.00%\n",
      "Epoch[11/15], Step[600/600], Loss: 0.3505, Accuracy: 89.00%\n",
      "Epoch[12/15], Step[100/600], Loss: 0.5643, Accuracy: 90.00%\n",
      "Epoch[12/15], Step[200/600], Loss: 0.2586, Accuracy: 91.00%\n",
      "Epoch[12/15], Step[300/600], Loss: 0.4008, Accuracy: 90.00%\n",
      "Epoch[12/15], Step[400/600], Loss: 0.5762, Accuracy: 86.00%\n",
      "Epoch[12/15], Step[500/600], Loss: 0.3889, Accuracy: 89.00%\n",
      "Epoch[12/15], Step[600/600], Loss: 0.2895, Accuracy: 88.00%\n",
      "Epoch[13/15], Step[100/600], Loss: 0.3846, Accuracy: 88.00%\n",
      "Epoch[13/15], Step[200/600], Loss: 0.3518, Accuracy: 91.00%\n",
      "Epoch[13/15], Step[300/600], Loss: 0.4496, Accuracy: 91.00%\n",
      "Epoch[13/15], Step[400/600], Loss: 0.8220, Accuracy: 82.00%\n",
      "Epoch[13/15], Step[500/600], Loss: 0.5455, Accuracy: 90.00%\n",
      "Epoch[13/15], Step[600/600], Loss: 0.5667, Accuracy: 87.00%\n",
      "Epoch[14/15], Step[100/600], Loss: 0.7726, Accuracy: 90.00%\n",
      "Epoch[14/15], Step[200/600], Loss: 0.3259, Accuracy: 90.00%\n",
      "Epoch[14/15], Step[300/600], Loss: 0.4907, Accuracy: 91.00%\n",
      "Epoch[14/15], Step[400/600], Loss: 0.5697, Accuracy: 88.00%\n",
      "Epoch[14/15], Step[500/600], Loss: 0.5462, Accuracy: 88.00%\n",
      "Epoch[14/15], Step[600/600], Loss: 0.3004, Accuracy: 91.00%\n",
      "Epoch[15/15], Step[100/600], Loss: 0.7018, Accuracy: 82.00%\n",
      "Epoch[15/15], Step[200/600], Loss: 0.5014, Accuracy: 86.00%\n",
      "Epoch[15/15], Step[300/600], Loss: 0.7160, Accuracy: 83.00%\n",
      "Epoch[15/15], Step[400/600], Loss: 0.4617, Accuracy: 90.00%\n",
      "Epoch[15/15], Step[500/600], Loss: 0.6586, Accuracy: 85.00%\n",
      "Epoch[15/15], Step[600/600], Loss: 0.3984, Accuracy: 89.00%\n"
     ]
    }
   ],
   "source": [
    "#quiz 4\n",
    "for epoch in range(training_epochs):\n",
    "    for i,(imgs,labels) in enumerate(train_loader): # X=imgs, Y=labels\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        imgs = imgs.view(-1,28*28).to(device)\n",
    "        \n",
    "        outputs = linear(imgs)\n",
    "        loss = criterion(outputs,labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _,argmax = torch.max(outputs, 1)\n",
    "        accuracy = (labels == argmax).float().mean()\n",
    "        \n",
    "        if (i+1)%100==0:\n",
    "            print('Epoch[{}/{}], Step[{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch+1,training_epochs,i+1, len(train_loader), loss.item(), accuracy.item()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01adb59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for 10000 images: 89.65%\n"
     ]
    }
   ],
   "source": [
    "#quiz 5\n",
    "#test\n",
    "linear.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i,(imgs,labels) in enumerate(test_loader):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        imgs = imgs.view(-1,28*28)\n",
    "        \n",
    "        outputs = linear(imgs)\n",
    "        \n",
    "        _,argmax = torch.max(outputs, 1) #max()를 통해 최종 출력이 가장 높은 class 선택\n",
    "        total += imgs.size(0)\n",
    "        correct += (labels == argmax).sum().item()\n",
    "    print('Test accuracy for {} images: {:.2f}%'.format(total, correct / total *100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
